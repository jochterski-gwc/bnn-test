{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["\n", "import pandas as pd\n", "from sklearn.neural_network import MLPClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import  confusion_matrix, classification_report\n", "from collections import defaultdict\n", "\n", "# Load the training dataset\n", "train_data = pd.read_csv('fashion_mnist_20bal_train.csv')\n", "\n", "# Separate the data (features) and the classes\n", "X_train = train_data.drop('class', axis=1)  # Features (all columns except the first one)\n", "X_train = X_train / 255.0\n", "y_train = train_data['class']   # Target (first column)\n", "\n", "# Load the testing dataset\n", "test_data = pd.read_csv('fashion_mnist_20bal_test.csv')\n", "\n", "# Separate the data (features) and the classes\n", "X_test = test_data.drop('class', axis=1)  # Features (all columns except the first one)\n", "X_test = X_test / 255.0\n", "y_test = test_data['class']   # Target (first column)\n", "\n", "neural_net_model = MLPClassifier(hidden_layer_sizes=(8), random_state=42, tol=0.005)\n", "\n", "neural_net_model.fit(X_train, y_train)\n", "# ABC Determine model architecture \n", "layer_sizes = [neural_net_model.coefs_[0].shape[0]]  # Start with the input layer size\n", "layer_sizes += [coef.shape[1] for coef in neural_net_model.coefs_]  # Add sizes of subsequent layers\n", "layer_size_str = \" x \".join(map(str, layer_sizes))\n", "print(f\"Layer sizes: {layer_size_str}\")\n", "\n", "# predict the classes from the training and test sets\n", "y_pred_train = neural_net_model.predict(X_train)\n", "y_pred = neural_net_model.predict(X_test)\n", "\n", "# Create dictionaries to hold total and correct counts for each class\n", "correct_counts = defaultdict(int)\n", "total_counts = defaultdict(int)\n", "overall_correct = 0\n", "\n", "# Count correct test predictions for each class\n", "for true, pred in zip(y_test, y_pred):\n", "    total_counts[true] += 1\n", "    if true == pred:\n", "        correct_counts[true] += 1\n", "        overall_correct += 1\n", "\n", "# For comparison, count correct _training_ set predictions\n", "total_counts_training = 0\n", "correct_counts_training = 0\n", "for true, pred in zip(y_train, y_pred_train):\n", "    total_counts_training += 1\n", "    if true == pred:\n", "        correct_counts_training += 1\n", "\n", "# Calculate and print accuracy for each class and overall test accuracy\n", "for class_id in sorted(total_counts.keys()):\n", "    accuracy = correct_counts[class_id] / total_counts[class_id] * 100\n", "    print(f\"Accuracy for class {class_id}: {accuracy:3.0f}%\")\n", "print(f\"----------\")\n", "overall_accuracy = overall_correct / len(y_test) * 100\n", "print(f\"Overall Test Accuracy: {overall_accuracy:3.1f}%\")\n", "overall_training_accuracy = correct_counts_training / total_counts_training * 100\n", "print(f\"Overall Training Accuracy: {overall_training_accuracy:3.1f}%\")\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 4}
